{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create vector store index\n",
    "\n",
    "This notebook can be used to create and save a vector index creates using text-embedding-ada-002 from OpenAI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to root\n",
    "path_to_root = '/work/PernilleHÃ¸jlundBrams#8577/NLP_2023_P'\n",
    "\n",
    "# To API key file\n",
    "path_to_key = f'{path_to_root}/config/keys.txt'\n",
    "\n",
    "# To data folder\n",
    "path_to_data = f'{path_to_root}/data'\n",
    "\n",
    "# To where you want to store vector index\n",
    "path_to_vector_store = f'{path_to_root}/index'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(f'{path_to_data}/articles.csv', sep = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create context chunks from documents\n",
    "This section converts the .csv file containing newsarticles into smaller chunks containing the *article body* as the main text and *author*, *URL*, *source*, *date published* and *title* in a metadata dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, Document\n",
    "\n",
    "# Convert the DataFrame into a list of Document objects that the index can understand\n",
    "documents = [Document(text=row['Article Body'],\n",
    "                      metadata={'title': row['Article Header'],\n",
    "                                'source': row['Source'],\n",
    "                                'author': row['Author'],\n",
    "                                'date': row['Published Date'],\n",
    "                                'url': row['Url']}) for index, row in df.iterrows()] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create servicecontex for the vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    ServiceContext,\n",
    "    OpenAIEmbedding,\n",
    "    PromptHelper,\n",
    ")\n",
    "from llama_index.text_splitter import SentenceSplitter\n",
    "\n",
    "# --- Sentencesplitter to split into chunks\n",
    "text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split documents into nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = text_splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_test = pd.DataFrame(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_test[7][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_test.to_csv(f\"{path_to_root}/data/prelim_dataframes/nodes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create VectorStore index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(f'{path_to_root}/src')\n",
    "\n",
    "# from utils import read_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Load API key\n",
    "# api_key = read_api_key(path_to_key)\n",
    "\n",
    "# import os\n",
    "\n",
    "# # Set the OpenAI API key in the environment variables\n",
    "# os.environ[\"OPENAI_API_KEY\"] = api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Generate vector index\n",
    "# index = VectorStoreIndex(nodes,show_progress = True)\n",
    "\n",
    "# # --- Persist index to disk\n",
    "# index.storage_context.persist(\"full_dataset_nodes_index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-e23-exam_new",
   "language": "python",
   "name": "nlp-e23-exam_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
